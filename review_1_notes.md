> A recommendation is made that is well-reasoned and supported by the data.
>
> Your answer is correct though the rationale is not when discussing the net conversion: The problem is not just the fact that we don’t have statistical significance (without statistical significance we are not able to say anything about the metric therefore we don’t know if the change is good or bad). It is true that there has been no statistically significant change, but the confidence interval does include the negative of the practical significance boundary. That is, it's possible that this number went down by an amount that would matter to the business. Is this an acceptable risk in order to launch? (The answer is straight forward if we consider the second part of our hypothesis)
>
> he report provides good justification for the choice of whether to use the Bonferroni correction. The answer is correct, this section does not meet specifications however because the rationale is not the proper one. The fact that we have ‘only two correlated metrics’ is not a good reason for deciding if a correction should be applied or not, that should depend on a sound statistical rationale. It is correct that the metrics might be correlated, that is not the proper reason for choosing or not choosing Bonferroni though.
>
> Let me indulge in this as this is one of the most complex concepts involved in this exam: To propose your recommendations you will, correctly, consider both the net and gross conversion. That is because, in order to launch, you would need them both to match our expectations (decrease in gross conversion and no decrease in net conversion). So we are in the case where more metrics need to be all matching what we expect in order to launch. The case where all metrics need to be relevant in order to launch is not the same as the case where any metrics can be relevant. In fact it is the exact opposite: For the former the risk of a Type II error increases as the number of metrics increase, for the latter the risk of a Type I error increases.
>
> Let me help with an example:
>
> Let’s imagine we have 20 metrics, and let's imagine we decide we want all of them to match expectations (like in our case, where we need both metrics to behave as expected in order to launch). Let's imagine 19 do what we expect, but one fails to reject. Which is our risk? At 95% confidence we have a 5% chance of failure to reject a false null hypothesis (Type II error). That is, we risk not to launch because one metric (out of 20) didn’t behave as expected just by chance. Bonferroni not designed for this. Conversely if we were to launch the experiment when any metric would match our expectations (so we would launch if just one metric out of 20 does what we expect) then we would have to use Bonferroni: Out of 20 metrics, the risk that just one rejects the null by pure chance (Type I error), would be very high. Bonferroni is designed to reduce this type of risk.
>
> Each metric has a clear and well-reasoned explanation of why it was or was not chosen as an invariant metric and as an evaluation metric.
>
> As for theNumber of user-ids: I'm not sure regarding the meaning of the sentence: " And it’s not good for evaluation because this experiment has different focus." Could you please provide more details? The number of user IDs is actually usable as evaluation metric because it would track the first part of the hypothesis, namely that we will reduce the number of students to continue past the free trial. It is not the best metric as it is not normalized but it could be an evaluation metric.
>
> Optional: Please note that Click-through-probability is actually better than number of clicks as it normalizes to the size of the control and experiment group.
>
> The report clearly states what results we look for in order to launch the experiment and the stated results are aligned with the experiment goals. Please note that in the 2nd part of our hypothesis, the one addressed by the net conversion, it is stated: “…without significantly reducing the number of students to continue past the free trial and eventually complete the course. “ Therefore it is not correct to expect for net conversion to increase, what the hypothesis requires is for the net conversion not to decrease in order to launch, which is not the same.
